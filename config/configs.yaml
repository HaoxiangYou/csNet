general:
  seed: 0
  device: "cuda"

training:
  batch_size: 16
  epochs: 20
  optimizor:
    lr: 0.01
    momentum: 0.9
    weight_decay: 1.e-5
    nesterov: True
    lr_decay: 0.95
    
    # the learning rate will not decay after this times of epochs
    end_epoch: 50

dataset:
  shuffle: True
  apply_transformation: True

  # the pecentatages of dataset being used
  dataset_size: 1

networks:
  # number of individual networks
  number_of_models: 16

  transforms:
    # fixed transforms generate policy: 
    # CIFR10:use same CIFR10 autoaugmentation as torch implementation
    # Random:use my random generation policy
    policy: CIFR10

    include_identity: True

  # size of hidden layer
  c1: 96
  c2: 192

  # dropout ratio
  d1: 0.2
  d2: 0.5

paths:
  #pre-trained_model
  model_path: null

  #pre-optimizor info
  optimizer_path: null

  #pre-determined fixed transforms path
  transforms_path: null

  #directory to save the model
  save_directory: "../pretrained_model"


